{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28a3e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a44196e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDIL_Block(nn.Module):\n",
    "    def __init__(self, c_in, c_out, ks, pad, dil):\n",
    "        super(CDIL_Block, self).__init__()\n",
    "        self.conv = weight_norm(nn.Conv1d(c_in, c_out, ks, padding=pad, dilation=dil, padding_mode='circular'))\n",
    "        self.conv.weight.data.normal_(0, 0.01)\n",
    "        self.conv.bias.data.normal_(0, 0.01)\n",
    "\n",
    "        self.res = nn.Conv1d(c_in, c_out, kernel_size=(1,)) if c_in != c_out else None\n",
    "        if self.res is not None:\n",
    "            self.res.weight.data.normal_(0, 0.01)\n",
    "            self.res.bias.data.normal_(0, 0.01)\n",
    "\n",
    "        self.nonlinear = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        res = x if self.res is None else self.res(x)\n",
    "        return self.nonlinear(out) + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c156bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDIL_ConvPart(nn.Module):\n",
    "    def __init__(self, dim_in, hidden_channels, ks=3):\n",
    "        super(CDIL_ConvPart, self).__init__()\n",
    "        layers = []\n",
    "        num_layer = len(hidden_channels)\n",
    "        for i in range(num_layer):\n",
    "            this_in = dim_in if i == 0 else hidden_channels[i - 1]\n",
    "            this_out = hidden_channels[i]\n",
    "            this_dilation = 2 ** i\n",
    "            this_padding = int(this_dilation * (ks - 1) / 2)\n",
    "            layers += [CDIL_Block(this_in, this_out, ks, this_padding, this_dilation)]\n",
    "        self.conv_net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d60927",
   "metadata": {},
   "source": [
    "# 1. cdil-cnn convolutional part outputs the same size(length) as the input sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58ce6699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 100])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEQ_LENGTH = 100  # remain unchanged\n",
    "INPUT_DIM = 10\n",
    "BATCH = 32\n",
    "x = torch.rand(BATCH, INPUT_DIM, SEQ_LENGTH)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6feb2a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 50, 100])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HIDDEN_CHANNEL = 50\n",
    "LAYER = 4\n",
    "cdil_conv_part1 = CDIL_ConvPart(INPUT_DIM, [HIDDEN_CHANNEL] * LAYER)\n",
    "y_conv = cdil_conv_part1(x)\n",
    "y_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "529edc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 40, 100])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdil_conv_part2 = CDIL_ConvPart(INPUT_DIM, [20, 30, 40])\n",
    "y_conv = cdil_conv_part2(x)\n",
    "y_conv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39ff4bc",
   "metadata": {},
   "source": [
    "# 2. cdil-cnn model (classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cf36d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDIL_CNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_channels, kernel_size=3, use_embed=False, char_vocab=None):\n",
    "        super(CDIL_CNN, self).__init__()\n",
    "\n",
    "        self.use_embed = use_embed\n",
    "        if self.use_embed:\n",
    "            self.embedding = nn.Embedding(char_vocab, input_size)\n",
    "\n",
    "        self.conv = CDIL_ConvPart(input_size, num_channels, kernel_size)\n",
    "        self.classifier = nn.Linear(num_channels[-1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_embed:\n",
    "            x = self.embedding(x)\n",
    "            x = x.permute(0, 2, 1).to(dtype=torch.float)\n",
    "        y_conv = self.conv(x)  # x, y: num, channel(dim), length\n",
    "        y = self.classifier(torch.mean(y_conv, dim=2))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccd2759",
   "metadata": {},
   "source": [
    "## using input sequences without embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6afea0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 200])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEQ_LENGTH = 200\n",
    "INPUT_DIM = 3\n",
    "OUTPUT_CLASS = 11\n",
    "BATCH = 64\n",
    "HIDDEN_CHANNEL = 20\n",
    "LAYER = 3\n",
    "x = torch.rand(BATCH, INPUT_DIM, SEQ_LENGTH)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be64fde5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 11])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdil_model_noembed = CDIL_CNN(INPUT_DIM, OUTPUT_CLASS, [HIDDEN_CHANNEL] * LAYER)\n",
    "y = cdil_model_noembed(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab9b0b7",
   "metadata": {},
   "source": [
    "## using input sequences with embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80876fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_EMBED = True\n",
    "CHAR_VOCAB = 5\n",
    "\n",
    "SEQ_LENGTH = 300\n",
    "EMBED_DIM = 4\n",
    "OUTPUT_CLASS = 13\n",
    "BATCH = 16\n",
    "HIDDEN_CHANNEL = 30\n",
    "LAYER = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fd5f6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 300])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(CHAR_VOCAB, (BATCH, SEQ_LENGTH))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed3e8794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 13])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdil_model_embed = CDIL_CNN(EMBED_DIM, OUTPUT_CLASS, [HIDDEN_CHANNEL] * LAYER, use_embed=USE_EMBED, char_vocab=CHAR_VOCAB)\n",
    "y = cdil_model_embed(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad2b1d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cdil] *",
   "language": "python",
   "name": "conda-env-cdil-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
